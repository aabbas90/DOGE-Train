#!/bin/bash

#SBATCH -p gpu20
##SBATCH --ntasks=16
#SBATCH --nodes=1
##SBATCH --mem=200000
#SBATCH --gres gpu:1
#SBATCH -t 0-11:59:59
#SBATCH -o out_primal/slurm/%j_qaplib.out
####SBATCH --signal=SIGUSR1@90

# Make conda available:
. ~/.bashrc_private
eval "$(conda shell.bash hook)"
# Activate a conda environment:
conda activate LearnDBCA

FEATURE_EXTRACTOR_DEPTH=1
PRIMAL_PRED_DEPTH=1
VAR_FEATURE_DIM=32
CON_FEATURE_DIM=16
EDGE_FEATURE_DIM=8
NUM_HIDDEN_LAYERS_EDGE=1
NUM_DUAL_ITR=500
GRAD_DUAL_ITR_MAX_ITR=50
LR=1e-4
NUM_ROUNDS_WITH_GRAD=3
MIN_PERTURBATION=1e-4
MAX_NUM_ROUNDS=20
USE_LSTM=True
LOSS_DISCOUNT_FACTOR=0.1
MM_AGR_LOSS_WEIGHT=0.01
MM_TANH_MULT=1e3
FOLDER_NAME=${FEATURE_EXTRACTOR_DEPTH}_${PRIMAL_PRED_DEPTH}_${VAR_FEATURE_DIM}_${CON_FEATURE_DIM}_${EDGE_FEATURE_DIM}_${NUM_HIDDEN_LAYERS_EDGE}_${NUM_DUAL_ITR}_${GRAD_DUAL_ITR_MAX_ITR}_${LR}_${NUM_ROUNDS_WITH_GRAD}_${MIN_PERTURBATION}_${MAX_NUM_ROUNDS}_${USE_LSTM}_${LOSS_DISCOUNT_FACTOR}_${MM_AGR_LOSS_WEIGHT}_${MM_TANH_MULT}

echo ${FOLDER_NAME}
#
python train_primal_rounding.py --test-non-learned \
    --config-file config_primal/config_qaplib.py \
    MODEL.FEATURE_EXTRACTOR_DEPTH ${FEATURE_EXTRACTOR_DEPTH} \
    MODEL.PRIMAL_PRED_DEPTH ${PRIMAL_PRED_DEPTH} \
    MODEL.VAR_FEATURE_DIM ${VAR_FEATURE_DIM} \
    MODEL.CON_FEATURE_DIM ${CON_FEATURE_DIM} \
    MODEL.EDGE_FEATURE_DIM ${EDGE_FEATURE_DIM} \
    MODEL.NUM_HIDDEN_LAYERS_EDGE ${NUM_HIDDEN_LAYERS_EDGE} \
    MODEL.USE_LSTM_VAR ${USE_LSTM} \
    TRAIN.LOSS_DISCOUNT_FACTOR ${LOSS_DISCOUNT_FACTOR} \
    TRAIN.NUM_ROUNDS ${MAX_NUM_ROUNDS} \
    TRAIN.NUM_DUAL_ITERATIONS ${NUM_DUAL_ITR} \
    TRAIN.GRAD_DUAL_ITR_MAX_ITR ${GRAD_DUAL_ITR_MAX_ITR} \
    TRAIN.BASE_LR ${LR} \
    TRAIN.NUM_ROUNDS_WITH_GRAD ${NUM_ROUNDS_WITH_GRAD} \
    TRAIN.MIN_PERTURBATION ${MIN_PERTURBATION} \
    TRAIN.MM_AGR_LOSS_WEIGHT ${MM_AGR_LOSS_WEIGHT} \
    TRAIN.MM_TANH_MULT ${MM_TANH_MULT} \
    OUT_REL_DIR QAPLIB/nobackup/v2_overfit_single_${FOLDER_NAME}

exit 0